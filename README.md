# BuildingInPublic
I want to see how strong community work can be by attempting to launch an app that is build by everyone that wants to contribute. 
THe working title will be "VisionVox"

Context: I'm working for WeAreDevelopers and everyone that knows our WeAreDevelopers World Congress knows our main stage and the other stages with lots of high quality speakers and content.
Someone of the community sparked in idea in me. WHy not having an AI tool that supports speakers on stage, on the fly, without having a hand-held tool like a clicker or just using rudimental 
commands like "switch" or "next slide". 

I want to create a tool - kind of a "Jarvis" from Iron Man, that listens to your speak in real-time and knows exaclty when to switch slides, when to get back to a specific slide or topic,
what to create to on the fly to support the speakers vision and content, by for example, generating a chart, an image, a mind-map, whatevery, to support the speakers vision if needed. 

Especially in Q&A-Sessions where there's a lot of Back and Forth, where you could let the AI tool summarize some points from speaker as well as from the audience. 

There is even more in the future, I'd like to realize based on this tool, 
but for now, I'd like to focus on "real-time slide switching based on the context" / "on the words that are thought out loud"
